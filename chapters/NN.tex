% !TeX root = ../main.tex

\chapter{神经网络}
\label{chap:NN}

为了识别信号中的位移喷注（displaced jets）与类标准模型（SM-like）喷注以及由束流背景（BIB）产生的伪喷注，训练了一个逐喷注（per-jet）的神经网络（NN）。
该神经网络在隐藏区域（Hidden Sector）模型信号、标准模型多喷注（SM Multi-jets）以及 BIB 的混合样本上进行训练。
神经网络的输入变量为与每个喷注相关的低级特征，涵盖整个 ATLAS 探测器的信息，包括径迹、量能器以及 μ 子谱仪相关信息。
训练前对每个变量进行了预处理，以确保神经网络训练的最优效果。
网络结构选用基于 Transformer\cite{vaswani2023attentionneed} 的图神经网络（GNN）。
训练采用 Pytorch\cite{paszke2019pytorchimperativestylehighperformance} 框架，
并使用 Optuna\cite{akiba2019optunanextgenerationhyperparameteroptimization} 框架进行超参数（hyperparameter）优化。
训练结果经过评估以排除过拟合现象，并在所用信号样本上相较于此前的网络性能有所提升。

训练使用的信号区域（signal region）数据集包括来自探测器的 BIB 数据（见\autoref{sec:detector_data}）
和带有真相信息（truth value）的信号与标准模型多喷注（简记为 QCD）模拟数据（见\autoref{sec:MC}）。
训练中使用的喷注均为 clean 喷注，其定义见\autoref{sec:jet_preselection}。
信号喷注为隐藏区域（Hidden Sector）模型中由一系列不同的$m_\Phi$、$m_s$、$c\tau$参数生成的模拟数据，
其中 $m_\Phi$ 为中介粒子质量，$m_s$ 为 LLP 的质量，$c\tau$ 为 LLP 衰变长度。
训练阶段仅使用事件编号为奇数的信号事件，偶数编号的事件则用于后续分析流程，以避免因数据重叠而引发的偏差，确保最终结果的客观性和可信度。
对于 QCD 喷注，训练样本来自 JZ2W、JZ3W 和 JZ4W 样本，
这些样本覆盖了 $p_T$ 范围为 60 GeV 至 800 GeV 的双喷注（dijet）事件，叠加的 pileup 喷注将该范围的下界扩展至 40 GeV。
BIB 喷注训练样本选取触发 HLT CalRatio 触发器但未通过 HLT BIB 抑制算法的事件。
随后通过 $\Delta R$ 匹配离线喷注与触发喷注，匹配成功并满足公共选择条件的喷注被标记为 BIB 喷注。

控制区域（control region）数据集包括来自探测器的数据和带有真相信息的 QCD 模拟数据。

主数据集总计有 2.09M jets，其中 766k jets 属于信号集、660k jets 属于 QCD 集、660k jets 属于 BIB 集。
CR有 449k jets，其中 223k jets 来自模拟、226k jets 来自探测器。

由于信号与背景喷注可通过 ATLAS 探测器的各个子系统加以刻画，因此神经网络也应当充分利用来自各子探测器的信息。
NN 输入变量的概述如下，详细变量见\autoref{cpm:NN_variables}：
\begin{itemize}
    \item 位于喷注轴线 $\Delta R < 0.2$ 范围内的径迹的空间位置、动量、碰撞参数（impact parameter）和径迹拟合质量参量；
    \item 与喷注相关联的拓扑集团（topo-clusters） 的动量、时间信息和空间位置；
    \item 喷注在电磁量能器与强子量能器各层的能量沉积比例；
    \item 距喷注 $\Delta \phi < 0.2$ 范围内的μ子段（muon segment）的空间与时间信息；
    \item 喷注本身的动量与空间位置。
\end{itemize}

训练前对输入变量进行预处理以减少训练事件之间的偏差，并调整变量分布以加快训练收敛速度。
预处理完成后，喷注输入至神经网络，网络输出对应于信号、QCD 或 BIB 的标签。
训练程序使用的是基于 TensorFlow 后端的 Keras 框架，因其提供了对复杂网络的高度自定义能力，同时保持了快速开发的优势。


\section{网络结构}
神经网络结构选用了两种模块组合：第一为一维卷积神经网络（1D CNN），作为特征提取器。卷积操作作用于每个子探测器变量形成的一维数组，分别针对跟踪器、量能器和缪子段输入，从而捕捉各输入变量间的相关性。第二部分为 LSTM 网络，其具备对连续输入之间关系的记忆能力（例如 TopoCluster 之间的联系），从而进一步利用各喷注中多个 topo-cluster、径迹段与缪子段之间的内部相关性。

各子网络的输出与喷注输入变量连接后输入至若干全连接层，最终网络输出三个预测值：signal weight、QCD weight 以及 BIB weight。网络结构参数通过超参数扫描选定。

此外，还在神经网络输出后添加了一个对抗网络（adversarial network），该网络用于在控制区中学习区分模拟喷注与真实数据喷注的特征，并将此反馈至主网络以抑制数据与 MC 的不一致性。这一对抗训练显著降低了数据与 MC 模型之间的差异，效果可见图 10 与图 11 中 BIB 分数的比较。网络结构图与对抗训练流程可见图 9。

训练过程分别针对低质量与高质量信号样本（low-mass 与 high-mass）独立进行。低质量样本中由于 $p_T$ 较低，难以与 QCD 或 BIB 背景区分，因此测试了联合与分别训练的效果，结果表明分开训练在信号判别效率方面表现更优。因此，低质量训练使用 $m_\tau = 60, 125, 200$ GeV 样本，高质量训练使用 $m_\tau = 400, 600, 1000$ GeV 样本。


\section{训练方法}


\section{结果}
最终训练效果可见图 12--14，分数越低表明被标记为该类别喷注的可能性越低，分数接近 1 则表示为该类别喷注的置信度越高。训练约经历 50 个 epoch（遍历完整训练集）收敛。有关神经网络输入建模的不确定性的系统评估流程见附录 B.9。

